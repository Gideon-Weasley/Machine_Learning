{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoNb1XKS2qtFHYmShNblRc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gideon-Weasley/Machine_Learning/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "Rf9hMhON_F9W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the dataset\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes = load_diabetes()  # by default - numpy array - if we want as pandas df we should give an argument as_frame=True\n",
        "\n",
        "X=diabetes.data\n",
        "y=diabetes.target\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki6EVbocKYsv",
        "outputId": "4a5c29ca-7331-42bf-e043-d2ca0bb56795"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076\n",
            "  -0.04340085 -0.00259226  0.01990749 -0.01764613]\n",
            " [-0.00188202 -0.04464164 -0.05147406 -0.02632753 -0.00844872 -0.01916334\n",
            "   0.07441156 -0.03949338 -0.06833155 -0.09220405]\n",
            " [ 0.08529891  0.05068012  0.04445121 -0.00567042 -0.04559945 -0.03419447\n",
            "  -0.03235593 -0.00259226  0.00286131 -0.02593034]\n",
            " [-0.08906294 -0.04464164 -0.01159501 -0.03665608  0.01219057  0.02499059\n",
            "  -0.03603757  0.03430886  0.02268774 -0.00936191]\n",
            " [ 0.00538306 -0.04464164 -0.03638469  0.02187239  0.00393485  0.01559614\n",
            "   0.00814208 -0.00259226 -0.03198764 -0.04664087]]\n",
            "[151.  75. 141. 206. 135.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the model class\n",
        "class myModel(nn.Module):\n",
        "  def __init__(self,in_features=10,out_features=1):\n",
        "    super().__init__()\n",
        "    self.out=nn.Linear(10,1)\n",
        "  def forward(self,x):\n",
        "    x=self.out(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "SmgjJv5_JWLJ"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(32)\n",
        "\n",
        "model=myModel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhcngkYONViw",
        "outputId": "35d73bf7-b674-4b9e-d14b-005b0ea4c98f"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "myModel(\n",
            "  (out): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=32)\n",
        "\n",
        "X_train=torch.FloatTensor(X_train)\n",
        "X_test=torch.FloatTensor(X_test)\n",
        "y_train = torch.FloatTensor(y_train).view(-1, 1)  # Reshape to (num_samples, 1)\n",
        "y_test = torch.FloatTensor(y_test).view(-1, 1)"
      ],
      "metadata": {
        "id": "yfacmO0-N1hA"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAufWLTCSvfN",
        "outputId": "577c12cc-2bef-4b62-95c8-1ec0ddde0d05"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.MSELoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.05)"
      ],
      "metadata": {
        "id": "L-pj_hn6OgRS"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train our model\n",
        "epoch=1300\n",
        "for i in range(epoch):\n",
        "  y_pred=model(X_train)\n",
        "  loss=criterion(y_pred,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i%10==0:\n",
        "    print(f'epoch: {i} loss: {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A3QckPYQB7d",
        "outputId": "e3b62aca-3f95-40c6-b83d-e182e23d5d3c"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 6735.03564453125\n",
            "epoch: 10 loss: 6679.005859375\n",
            "epoch: 20 loss: 6623.587890625\n",
            "epoch: 30 loss: 6568.84423828125\n",
            "epoch: 40 loss: 6514.8173828125\n",
            "epoch: 50 loss: 6461.52880859375\n",
            "epoch: 60 loss: 6408.982421875\n",
            "epoch: 70 loss: 6357.1796875\n",
            "epoch: 80 loss: 6306.1162109375\n",
            "epoch: 90 loss: 6255.78564453125\n",
            "epoch: 100 loss: 6206.1806640625\n",
            "epoch: 110 loss: 6157.29296875\n",
            "epoch: 120 loss: 6109.11767578125\n",
            "epoch: 130 loss: 6061.64599609375\n",
            "epoch: 140 loss: 6014.87060546875\n",
            "epoch: 150 loss: 5968.78564453125\n",
            "epoch: 160 loss: 5923.380859375\n",
            "epoch: 170 loss: 5878.65185546875\n",
            "epoch: 180 loss: 5834.5908203125\n",
            "epoch: 190 loss: 5791.1904296875\n",
            "epoch: 200 loss: 5748.44287109375\n",
            "epoch: 210 loss: 5706.341796875\n",
            "epoch: 220 loss: 5664.87939453125\n",
            "epoch: 230 loss: 5624.0498046875\n",
            "epoch: 240 loss: 5583.84423828125\n",
            "epoch: 250 loss: 5544.25732421875\n",
            "epoch: 260 loss: 5505.28125\n",
            "epoch: 270 loss: 5466.9091796875\n",
            "epoch: 280 loss: 5429.13427734375\n",
            "epoch: 290 loss: 5391.9501953125\n",
            "epoch: 300 loss: 5355.3486328125\n",
            "epoch: 310 loss: 5319.32421875\n",
            "epoch: 320 loss: 5283.87060546875\n",
            "epoch: 330 loss: 5248.9794921875\n",
            "epoch: 340 loss: 5214.6455078125\n",
            "epoch: 350 loss: 5180.86181640625\n",
            "epoch: 360 loss: 5147.62158203125\n",
            "epoch: 370 loss: 5114.91943359375\n",
            "epoch: 380 loss: 5082.74755859375\n",
            "epoch: 390 loss: 5051.10009765625\n",
            "epoch: 400 loss: 5019.97119140625\n",
            "epoch: 410 loss: 4989.353515625\n",
            "epoch: 420 loss: 4959.2421875\n",
            "epoch: 430 loss: 4929.63037109375\n",
            "epoch: 440 loss: 4900.51123046875\n",
            "epoch: 450 loss: 4871.8798828125\n",
            "epoch: 460 loss: 4843.72998046875\n",
            "epoch: 470 loss: 4816.0546875\n",
            "epoch: 480 loss: 4788.84912109375\n",
            "epoch: 490 loss: 4762.1064453125\n",
            "epoch: 500 loss: 4735.8212890625\n",
            "epoch: 510 loss: 4709.98681640625\n",
            "epoch: 520 loss: 4684.5986328125\n",
            "epoch: 530 loss: 4659.650390625\n",
            "epoch: 540 loss: 4635.1357421875\n",
            "epoch: 550 loss: 4611.05029296875\n",
            "epoch: 560 loss: 4587.3857421875\n",
            "epoch: 570 loss: 4564.138671875\n",
            "epoch: 580 loss: 4541.30224609375\n",
            "epoch: 590 loss: 4518.87158203125\n",
            "epoch: 600 loss: 4496.84130859375\n",
            "epoch: 610 loss: 4475.20556640625\n",
            "epoch: 620 loss: 4453.9580078125\n",
            "epoch: 630 loss: 4433.09423828125\n",
            "epoch: 640 loss: 4412.60791015625\n",
            "epoch: 650 loss: 4392.49365234375\n",
            "epoch: 660 loss: 4372.74658203125\n",
            "epoch: 670 loss: 4353.3603515625\n",
            "epoch: 680 loss: 4334.33203125\n",
            "epoch: 690 loss: 4315.65380859375\n",
            "epoch: 700 loss: 4297.3212890625\n",
            "epoch: 710 loss: 4279.3291015625\n",
            "epoch: 720 loss: 4261.67236328125\n",
            "epoch: 730 loss: 4244.34619140625\n",
            "epoch: 740 loss: 4227.34521484375\n",
            "epoch: 750 loss: 4210.6630859375\n",
            "epoch: 760 loss: 4194.2958984375\n",
            "epoch: 770 loss: 4178.2392578125\n",
            "epoch: 780 loss: 4162.4873046875\n",
            "epoch: 790 loss: 4147.03515625\n",
            "epoch: 800 loss: 4131.87744140625\n",
            "epoch: 810 loss: 4117.009765625\n",
            "epoch: 820 loss: 4102.42822265625\n",
            "epoch: 830 loss: 4088.126708984375\n",
            "epoch: 840 loss: 4074.099853515625\n",
            "epoch: 850 loss: 4060.345947265625\n",
            "epoch: 860 loss: 4046.857177734375\n",
            "epoch: 870 loss: 4033.6298828125\n",
            "epoch: 880 loss: 4020.6611328125\n",
            "epoch: 890 loss: 4007.943359375\n",
            "epoch: 900 loss: 3995.47412109375\n",
            "epoch: 910 loss: 3983.248291015625\n",
            "epoch: 920 loss: 3971.261962890625\n",
            "epoch: 930 loss: 3959.5107421875\n",
            "epoch: 940 loss: 3947.98876953125\n",
            "epoch: 950 loss: 3936.6943359375\n",
            "epoch: 960 loss: 3925.620361328125\n",
            "epoch: 970 loss: 3914.764892578125\n",
            "epoch: 980 loss: 3904.123291015625\n",
            "epoch: 990 loss: 3893.690185546875\n",
            "epoch: 1000 loss: 3883.462890625\n",
            "epoch: 1010 loss: 3873.4365234375\n",
            "epoch: 1020 loss: 3863.607666015625\n",
            "epoch: 1030 loss: 3853.9716796875\n",
            "epoch: 1040 loss: 3844.525390625\n",
            "epoch: 1050 loss: 3835.265625\n",
            "epoch: 1060 loss: 3826.18701171875\n",
            "epoch: 1070 loss: 3817.286376953125\n",
            "epoch: 1080 loss: 3808.560546875\n",
            "epoch: 1090 loss: 3800.00537109375\n",
            "epoch: 1100 loss: 3791.6171875\n",
            "epoch: 1110 loss: 3783.392333984375\n",
            "epoch: 1120 loss: 3775.328369140625\n",
            "epoch: 1130 loss: 3767.42041015625\n",
            "epoch: 1140 loss: 3759.665771484375\n",
            "epoch: 1150 loss: 3752.060791015625\n",
            "epoch: 1160 loss: 3744.602783203125\n",
            "epoch: 1170 loss: 3737.28759765625\n",
            "epoch: 1180 loss: 3730.112548828125\n",
            "epoch: 1190 loss: 3723.07470703125\n",
            "epoch: 1200 loss: 3716.17041015625\n",
            "epoch: 1210 loss: 3709.396240234375\n",
            "epoch: 1220 loss: 3702.75\n",
            "epoch: 1230 loss: 3696.228759765625\n",
            "epoch: 1240 loss: 3689.828857421875\n",
            "epoch: 1250 loss: 3683.548095703125\n",
            "epoch: 1260 loss: 3677.383056640625\n",
            "epoch: 1270 loss: 3671.331787109375\n",
            "epoch: 1280 loss: 3665.390625\n",
            "epoch: 1290 loss: 3659.5576171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "with torch.no_grad():\n",
        "  y_eval=model.forward(X_test)\n",
        "  loss=criterion(y_eval,y_test)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXJ2hwBaWqSl",
        "outputId": "44cdf349-8b88-434d-b431-5ef9aa99c1d1"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3210.7615)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from types import new_class\n",
        "#Giving new data\n",
        "new_data=torch.tensor([ 0.03807591 ,0.05068012  ,0.06169621 , 0.02187239, -0.0442235 , -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613])\n",
        "torch.no_grad()\n",
        "model.eval()\n",
        "pred=model(new_data)\n",
        "print(f'predicted value: {pred}') #real value 151"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSZlXnQiXvaD",
        "outputId": "40596490-a883-4d49-8567-b46124cc5c2d"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted value: tensor([161.7431], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    }
  ]
}